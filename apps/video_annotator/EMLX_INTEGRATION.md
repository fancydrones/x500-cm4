# EMLX (Metal GPU) Integration

**Date**: 2025-10-26
**Status**: âœ… COMPLETE - EMLX integrated with 1.8x speedup

## Summary

EMLX (Metal GPU acceleration) has been integrated into the video annotation pipeline, providing **80% faster inference** on macOS compared to EXLA (CPU).

## Benchmark Results

Performance comparison of YOLOX-Nano inference (50 iterations each):

| Backend | Average Latency | FPS | Speedup |
|---------|----------------|-----|---------|
| **EXLA (CPU)** | 103.3ms | 9.68 FPS | Baseline |
| **EMLX (Metal GPU)** | 57.4ms | 17.43 FPS | **1.8x faster** |

### Key Metrics

- **Speedup**: 1.80x (80% improvement)
- **Latency reduction**: 45.9ms saved per frame
- **FPS improvement**: 9.68 â†’ 17.43 (+80%)

## Implementation

### 1. Application Changes

**File**: [lib/video_annotator/application.ex](lib/video_annotator/application.ex)

Added automatic backend selection based on OS with optional config override:

```elixir
defp select_backend do
  # Check if backend explicitly configured
  case Application.get_env(:video_annotator, :nx_backend) do
    nil ->
      # Auto-detect based on OS (recommended)
      case :os.type() do
        {:unix, :darwin} ->
          # macOS - use Metal GPU acceleration (1.8x faster)
          EMLX.Backend

        _ ->
          # Linux (Raspberry Pi) - use CPU
          EXLA.Backend
      end

    backend when is_atom(backend) ->
      # Use explicitly configured backend
      backend
  end
end
```

The backend is selected at application startup:

```elixir
backend = select_backend()
Nx.global_default_backend(backend)
IO.puts("Using Nx backend: #{inspect(backend)}")
```

### 2. Configuration (Optional)

**File**: [config/config.exs](config/config.exs)

Backend is **auto-detected by default** - no configuration needed!

For testing or edge cases, you can override:

```elixir
# Force CPU backend (for testing)
config :video_annotator, :nx_backend, EXLA.Backend

# Force Metal GPU backend (macOS only)
config :video_annotator, :nx_backend, EMLX.Backend
```

**Recommendation**: Don't set this - let it auto-detect!

### 3. Dependency Changes

**File**: [mix.exs](mix.exs)

Updated EMLX from `:dev` only to always available (conditional on OS):

```elixir
# Neural network inference
{:yolo, ">= 0.2.0"},
{:nx, "~> 0.7"},
{:exla, "~> 0.9"},  # CPU backend (Linux/RPi)
{:emlx, "~> 0.2"},  # Metal GPU acceleration (macOS, 1.8x speedup)
```

## Impact on Performance

### Expected End-to-End Performance

With EMLX integration, the full pipeline performance improves:

**Previous (EXLA)**:
- Inference: ~130-180ms
- Total pipeline: ~6-7 FPS

**New (EMLX)**:
- Inference: ~70-100ms
- **Expected total pipeline: ~10-12 FPS** ðŸš€

This is a significant improvement for macOS development workflow!

### Components Affected

The speedup applies to:
- âœ… YOLO model inference
- âœ… Tensor preprocessing operations
- âœ… Any Nx operations in the pipeline

## Platform Support

| Platform | Backend | Notes |
|----------|---------|-------|
| **macOS** | EMLX.Backend | Metal GPU acceleration |
| **Linux (RPi)** | EXLA.Backend | CPU only |
| **Other** | EXLA.Backend | Fallback to CPU |

## Testing

### Benchmark Test

Run the comprehensive benchmark:

```bash
mix run test_emlx_benchmark.exs
```

This compares EXLA vs EMLX across 50 iterations and provides:
- Average, median, min, max latency
- FPS calculations
- Speedup analysis
- Recommendation

### Live Test

Run the web preview with EMLX:

```bash
mix run test_web_preview.exs
```

You should see:
```
Using Nx backend: EMLX.Backend
```

Monitor the frame processing logs to see improved FPS.

## Deployment Considerations

### macOS Development

âœ… **EMLX is ideal for development**:
- Faster iteration cycles
- Better debugging experience
- Improved web preview responsiveness

### Raspberry Pi Production

âœ… **EXLA automatically selected**:
- No code changes needed
- Backend selection is automatic based on OS
- RPi will use EXLA.Backend (CPU)

## Troubleshooting

### Issue: Backend not switching

**Symptom**: Still seeing `EXLA.Backend` on macOS

**Solution**: Ensure clean compile:
```bash
mix clean
mix compile
```

### Issue: EMLX compilation errors

**Symptom**: Errors about Metal or EMLX during compilation

**Solution**: EMLX requires macOS. On Linux, it will automatically use EXLA instead. No action needed.

### Issue: "Tensor implementation mismatch"

**Symptom**: `RuntimeError: cannot invoke Nx function because it relies on two incompatible tensor implementations`

**Solution**: This happens if model was loaded with one backend but used with another. The fix is to reload the model after switching backends (already handled in our implementation).

## Future Optimizations

Potential improvements for even better performance:

1. **Model quantization**: Convert to FP16 for Metal
2. **Batch processing**: Process multiple frames in parallel
3. **Async inference**: Overlap preprocessing and inference
4. **Metal Performance Shaders**: Direct MPSGraph integration

## References

- EMLX GitHub: https://github.com/elixir-nx/emlx
- Benchmark script: [test_emlx_benchmark.exs](test_emlx_benchmark.exs)
- Phase 0 completion: [PHASE_0_COMPLETE.md](PHASE_0_COMPLETE.md)

---

## Conclusion

âœ… **EMLX successfully integrated**
âœ… **1.8x speedup confirmed**
âœ… **Automatic platform-based selection**
âœ… **No changes needed for Raspberry Pi deployment**

The EMLX integration provides significant performance improvements for macOS development while maintaining portability to Raspberry Pi production deployments.
